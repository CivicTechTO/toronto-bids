{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'docx2txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# from pdfminer.converter import TextConverter\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# from pdfminer.layout import LAParams\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# from pdfminer.pdfdocument import PDFEncryptionError\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# import pdfplumber\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdocx2txt\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfitz\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'docx2txt'"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import magic\n",
    "import os\n",
    "import pathlib\n",
    "import subprocess\n",
    "from IPython.display import clear_output\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "# from pdfminer.converter import TextConverter\n",
    "# from pdfminer.layout import LAParams\n",
    "# from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "# from pdfminer.pdfpage import PDFPage\n",
    "# from pdfminer.pdfparser import PDFSyntaxError\n",
    "# from pdfminer.pdfdocument import PDFEncryptionError\n",
    "# import pdfplumber\n",
    "import docx2txt\n",
    "import fitz\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf_fitz(pdf_file_path):\n",
    "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "    with pdf_file_path.open('rb') as file:\n",
    "        with fitz.open(file) as pdf:\n",
    "            text = \"\"\n",
    "            for page in pdf:\n",
    "                text += page.get_text()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_text_from_pdf_pdfplumber(pdf_file_path):\n",
    "#     \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "#     with pdf_file_path.open('rb') as file:\n",
    "#         with pdfplumber.open(file) as pdf:\n",
    "#             text = \"\"\n",
    "#             for page in pdf.pages:\n",
    "#                 text += page.extract_text()\n",
    "#                 clear_output(wait=True)\n",
    "#                 print(\"Processed page\", page.page_number, \"for\", pdf_file_path.name)\n",
    "#         return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# def extract_text_from_pdf_pdfminer(pdf_file_path):\n",
    "#     \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "#     with pdf_file_path.open('rb') as file:\n",
    "#         resource_manager = PDFResourceManager()\n",
    "#         string_io = StringIO()\n",
    "#         pdf_converter = TextConverter(resource_manager, string_io, laparams=LAParams())\n",
    "#         page_interpreter = PDFPageInterpreter(resource_manager, pdf_converter)\n",
    "#         pages = PDFPage.get_pages(file, caching=True, check_extractable=False)\n",
    "\n",
    "#         for i, page in enumerate(pages):\n",
    "#             page_interpreter.process_page(page)\n",
    "#             clear_output(wait=True)\n",
    "#             print(\"Processed page\", i + 1, \"for\", pdf_file_path.name)\n",
    "#         text = string_io.getvalue()\n",
    "#         pdf_converter.close()\n",
    "#         string_io.close()\n",
    "#         return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_pdf(pdf: Path):\n",
    "    if 'repaired' in pdf.as_posix():\n",
    "        return pdf\n",
    "    ghostscript = \"gs\"\n",
    "    repaired_pdf = pdf.with_suffix(\".repaired.pdf\")\n",
    "    repair_command = [ghostscript, \"-q\", \"-dNOPAUSE\", \"-dBATCH\", \"-sDEVICE=pdfwrite\", \"-dPDFSETTINGS=/prepress\", \"-sOutputFile=\" + str(repaired_pdf), str(pdf)]\n",
    "    subprocess.run(repair_command, check=True)\n",
    "    return repaired_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def process_directory(root_dir: Path, progress: tqdm):\n",
    "    pdf_files = list(root_dir.rglob('*.pdf'))\n",
    "    docx_files = list(root_dir.rglob('*.docx'))\n",
    "    doc_files = list(root_dir.rglob('*.doc'))\n",
    "\n",
    "    for file in root_dir.rglob('*'):\n",
    "        if not file.is_file():\n",
    "            continue\n",
    "\n",
    "        mime_type = magic.from_file(file, mime=True)\n",
    "\n",
    "        if mime_type.startswith(\"text/\"):\n",
    "            parsed_file = file.with_suffix('.parsed.txt')\n",
    "            if parsed_file.exists() or file.suffix == '.html':\n",
    "                continue\n",
    "            process_text(file, parsed_file)\n",
    "            progress.update(1)\n",
    "\n",
    "    \n",
    "    for file in pdf_files:\n",
    "        parsed_file = file.with_suffix('.parsed.txt')\n",
    "        if parsed_file.exists():\n",
    "            continue\n",
    "        process_pdf(file, parsed_file)\n",
    "        progress.update(1)\n",
    "\n",
    "    for file in docx_files:\n",
    "        parsed_file = file.with_suffix('.parsed.txt')\n",
    "        if parsed_file.exists():\n",
    "            continue\n",
    "        process_docx(file, parsed_file)\n",
    "        progress.update(1)\n",
    "\n",
    "    for file in doc_files:\n",
    "        if parsed_file.exists():\n",
    "            continue\n",
    "        parsed_file = file.with_suffix('.parsed.txt')\n",
    "        process_doc(file, parsed_file)\n",
    "        progress.update(1)\n",
    "\n",
    "            \n",
    "def process_pdf(file, parsed_file):\n",
    "    try:\n",
    "        texts = extract_text_from_pdf_fitz(file)\n",
    "    except Exception as e:\n",
    "        repaired_pdf = repair_pdf(file)\n",
    "        texts = extract_text_from_pdf_fitz(repaired_pdf)\n",
    "    with open(parsed_file, 'w') as f:\n",
    "        f.write(texts)\n",
    "\n",
    "def process_docx(file, parsed_file):\n",
    "    texts = docx2txt.process(file)\n",
    "    with open(parsed_file, 'w') as f:\n",
    "        f.write(texts)\n",
    "\n",
    "def process_doc(file, parsed_file):\n",
    "    subprocess.run(['libreoffice', '--convert-to', 'txt', '--outdir', str(file.parent), str(file)], check=True)\n",
    "    txt_file = file.with_suffix('.txt')\n",
    "    with open(txt_file, 'r') as f:\n",
    "        texts = f.read()\n",
    "    txt_file.unlink()\n",
    "    with open(parsed_file, 'w') as f:\n",
    "        f.write(texts)\n",
    "\n",
    "def process_text(file, parsed_file):\n",
    "    with open(file, 'r', errors='ignore') as f:\n",
    "        texts = f.read()\n",
    "        with open(parsed_file, 'w') as f:\n",
    "            f.write(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def search_for_identical_pdfs(root_dir):\n",
    "    total_deleted = 0\n",
    "    \"\"\"Searches for identical PDF files in a directory and its subdirectories.\"\"\"\n",
    "    root_path = Path(root_dir)\n",
    "    pdf_hashes = {}\n",
    "    for file_path in root_path.rglob('*.pdf'):\n",
    "        with file_path.open('rb') as file:\n",
    "            pdf_hash = hashlib.sha1(file.read()).hexdigest()\n",
    "            if pdf_hash not in pdf_hashes:\n",
    "                pdf_hashes[pdf_hash] = [file_path]\n",
    "            else:\n",
    "                pdf_hashes[pdf_hash].append(file_path)\n",
    "    for pdf_hash, pdf_files in pdf_hashes.items():\n",
    "        if len(pdf_files) > 1:\n",
    "            print(f\"PDF with hash {pdf_hash} occurs {len(pdf_files)} times:\")\n",
    "            for pdf_file in pdf_files:\n",
    "                print(f\"  {pdf_file}\")\n",
    "            directory_count = {}\n",
    "            for pdf_file in pdf_files:\n",
    "                directory = pdf_file.parts[0:2]\n",
    "                if directory in directory_count:\n",
    "                    directory_count[directory] += 1\n",
    "                else:\n",
    "                    directory_count[directory] = 1\n",
    "            for directory, count in directory_count.items():\n",
    "                if count > 1:\n",
    "                    for pdf_file in pdf_files:\n",
    "                        if pdf_file.parts[0:2] == directory:\n",
    "                            os.remove(pdf_file)\n",
    "                            total_deleted += 1\n",
    "                            print(f\"  Deleted {pdf_file}\")\n",
    "                            pdf_files.remove(pdf_file)\n",
    "                            break\n",
    "\n",
    "            print()\n",
    "    print(f'Total deleted: {total_deleted}')\n",
    "\n",
    "#search_for_identical_pdfs('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400it [02:10, 29.25it/s]"
     ]
    }
   ],
   "source": [
    "root = Path('data')\n",
    "pb = tqdm()\n",
    "\n",
    "process_directory(root, pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
